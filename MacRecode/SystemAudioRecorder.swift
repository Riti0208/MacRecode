import Foundation
import AVFoundation
import ScreenCaptureKit
import OSLog

public enum RecordingMode {
    case microphoneOnly
    case systemAudioOnly
    case mixedRecording
}

public enum RecordingError: LocalizedError {
    case permissionDenied(String)
    case noDisplayFound
    case setupFailed(String)
    case recordingInProgress
    case screenCaptureKitError(Error)
    
    public var errorDescription: String? {
        switch self {
        case .permissionDenied(let details):
            return "ç”»é¢åéŒ²ã®æ¨©é™ãŒå¿…è¦ã§ã™ã€‚è©³ç´°: \(details)\n\nã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ > ç”»é¢åéŒ² ã§è¨±å¯ã—ã¦ãã ã•ã„ã€‚"
        case .noDisplayFound:
            return "éŒ²éŸ³å¯èƒ½ãªãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        case .setupFailed(let details):
            return "éŒ²éŸ³ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: \(details)"
        case .recordingInProgress:
            return "éŒ²éŸ³ãŒæ—¢ã«é–‹å§‹ã•ã‚Œã¦ã„ã¾ã™"
        case .screenCaptureKitError(let error):
            return "ScreenCaptureKitã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
        }
    }
}

@MainActor
public class SystemAudioRecorder: NSObject, ObservableObject, SCStreamDelegate, SCStreamOutput {
    @Published public private(set) var isRecording = false
    @Published public private(set) var currentRecordingURL: URL?
    @Published public private(set) var recordingMode: RecordingMode = .systemAudioOnly
    
    private var captureSession: SCStream?
    private var audioEngine: AVAudioEngine?
    private var audioFile: AVAudioFile?
    
    // ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³ç”¨ã®åˆ†é›¢ã•ã‚ŒãŸå¤‰æ•°
    private var microphoneEngine: AVAudioEngine?
    private var microphoneFile: AVAudioFile?
    
    // ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³æ™‚ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«URL
    private var systemTempURL: URL?
    private var micTempURL: URL?
    private var finalMixedURL: URL?
    private let logger = Logger(subsystem: "com.example.MacRecode", category: "SystemAudioRecorder")
    private let recordingQueue = DispatchQueue(label: "com.example.MacRecode.recording", qos: .userInitiated)
    private var lastAudioLogTime: Date?
    
    public override init() {
        super.init()
    }
    
    // MARK: - Recording Mode Management
    
    public func setRecordingMode(_ mode: RecordingMode) {
        guard !isRecording else { return }
        recordingMode = mode
    }
    
    // MARK: - Mixed Recording Integration
    
    public func startRecordingWithMode() async throws {
        switch recordingMode {
        case .systemAudioOnly:
            try await startSystemAudioRecording()
        case .microphoneOnly:
            try await startMicrophoneRecording()
        case .mixedRecording:
            // çœŸã®ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³: ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã¨ãƒã‚¤ã‚¯ã‚’ä¸¦è¡ŒéŒ²éŸ³
            logger.info("Mixed recording selected - starting dual audio capture")
            try await startMixedRecording()
        }
    }
    
    // MARK: - Microphone Recording Methods
    
    public func checkMicrophonePermission() async -> Bool {
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        logger.info("Current microphone permission status: \(status.rawValue)")
        
        switch status {
        case .authorized:
            logger.info("Microphone permission already granted")
            return true
        case .notDetermined:
            logger.info("Requesting microphone permission...")
            let granted = await AVCaptureDevice.requestAccess(for: .audio)
            logger.info("Microphone permission granted: \(granted)")
            return granted
        case .denied, .restricted:
            logger.error("Microphone permission denied or restricted")
            return false
        @unknown default:
            logger.error("Unknown microphone permission status")
            return false
        }
    }
    
    public func startMicrophoneRecording() async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        // ãƒã‚¤ã‚¯æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯
        let hasPermission = await checkMicrophonePermission()
        guard hasPermission else {
            throw RecordingError.permissionDenied("Microphone permission required")
        }
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ç”Ÿæˆï¼ˆDocumentsãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼‰
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let fileName = "Microphone_\(formatter.string(from: Date())).caf"
        let recordingURL = documentsPath.appendingPathComponent(fileName)
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        try FileManager.default.createDirectory(at: documentsPath, withIntermediateDirectories: true, attributes: nil)
        
        do {
            // ãƒã‚¤ã‚¯éŒ²éŸ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            try setupMicrophoneAudioEngine(outputURL: recordingURL)
            
            // éŒ²éŸ³é–‹å§‹
            try audioEngine?.start()
            
            // çŠ¶æ…‹ã‚’æ›´æ–°
            currentRecordingURL = recordingURL
            isRecording = true
            
            logger.info("ãƒã‚¤ã‚¯éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: \(fileName)")
            logger.info("ä¿å­˜å ´æ‰€: \(recordingURL.path)")
        } catch {
            // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            stopRecording()
            if let error = error as? RecordingError {
                throw error
            } else {
                throw RecordingError.setupFailed(error.localizedDescription)
            }
        }
    }
    
    public func startRecording() async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        // ãƒã‚¤ã‚¯æ¨©é™ãƒã‚§ãƒƒã‚¯
        await requestMicrophonePermission()
        
        // ç”»é¢éŒ²ç”»æ¨©é™ãƒã‚§ãƒƒã‚¯
        let hasPermission = await checkRecordingPermission()
        guard hasPermission else {
            let preflightResult = CGPreflightScreenCaptureAccess()
            throw RecordingError.permissionDenied("Preflight: \(preflightResult)")
        }
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ç”Ÿæˆï¼ˆDocumentsãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼‰
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let fileName = "MacRecode_\(formatter.string(from: Date())).caf"
        let recordingURL = documentsPath.appendingPathComponent(fileName)
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        try FileManager.default.createDirectory(at: documentsPath, withIntermediateDirectories: true, attributes: nil)
        
        do {
            // éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            try setupAudioEngine(outputURL: recordingURL)
            
            // éŒ²éŸ³é–‹å§‹
            try audioEngine?.start()
            
            // çŠ¶æ…‹ã‚’æ›´æ–°
            currentRecordingURL = recordingURL
            isRecording = true
            
            logger.info("éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: \(fileName)")
            logger.info("ä¿å­˜å ´æ‰€: \(recordingURL.path)")
        } catch {
            // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            stopRecording()
            if let error = error as? RecordingError {
                throw error
            } else {
                throw RecordingError.setupFailed(error.localizedDescription)
            }
        }
    }
    
    public func stopRecording() {
        guard isRecording else { return }
        
        logger.info("éŒ²éŸ³ã‚’åœæ­¢ä¸­...")
        
        // éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if let engine = audioEngine, engine.isRunning {
            engine.stop()
            engine.inputNode.removeTap(onBus: 0)  // ã‚¿ãƒƒãƒ—ã‚’å‰Šé™¤
            logger.info("Audio engine stopped")
        }
        
        // ScreenCaptureKit ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢
        Task {
            do {
                try await captureSession?.stopCapture()
            } catch {
                self.logger.error("Failed to stop capture session: \(error)")
            }
        }
        captureSession = nil
        
        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        audioFile = nil
        
        // ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        audioEngine = nil
        microphoneEngine = nil
        microphoneFile = nil
        systemTempURL = nil
        micTempURL = nil
        finalMixedURL = nil
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        isRecording = false
        
        if let url = currentRecordingURL {
            logger.info("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«: \(url.lastPathComponent)")
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
            do {
                let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
                if let fileSize = attributes[.size] as? Int64 {
                    logger.info("ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(fileSize) bytes")
                }
            } catch {
                logger.error("Failed to get file size: \(error.localizedDescription)")
            }
        }
    }
    
    private func requestMicrophonePermission() async {
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        logger.info("Current microphone permission status: \(status.rawValue)")
        
        switch status {
        case .authorized:
            logger.info("Microphone permission already granted")
            return
        case .notDetermined:
            logger.info("Requesting microphone permission...")
            let granted = await AVCaptureDevice.requestAccess(for: .audio)
            logger.info("Microphone permission granted: \(granted)")
        case .denied, .restricted:
            logger.error("Microphone permission denied or restricted")
        @unknown default:
            logger.error("Unknown microphone permission status")
        }
    }
    
    public func checkRecordingPermission() async -> Bool {
        // ã¾ãšãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆãƒã‚§ãƒƒã‚¯
        let canRecord = CGPreflightScreenCaptureAccess()
        logger.info("Screen capture preflight check: \(canRecord)")
        
        if !canRecord {
            // æ¨©é™ãŒãªã„å ´åˆã¯è¦æ±‚
            logger.info("Requesting screen capture access...")
            let granted = CGRequestScreenCaptureAccess()
            logger.info("Screen capture access granted: \(granted)")
            
            // æ¨©é™è¦æ±‚å¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†åº¦ç¢ºèª
            if granted {
                try? await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’å¾…æ©Ÿ
                let recheckResult = CGPreflightScreenCaptureAccess()
                logger.info("Screen capture recheck after grant: \(recheckResult)")
                return recheckResult
            }
            return granted
        }
        
        // æ¨©é™ãŒã‚ã£ã¦ã‚‚ã€å®Ÿéš›ã«ScreenCaptureKitãŒä½¿ãˆã‚‹ã‹ãƒ†ã‚¹ãƒˆ
        do {
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            logger.info("ScreenCaptureKit test successful: \(content.displays.count) displays found")
            return !content.displays.isEmpty
        } catch {
            logger.error("ScreenCaptureKit test failed: \(error.localizedDescription)")
            return false
        }
    }
    
    // MARK: - System Audio Recording Methods
    
    public func checkSystemAudioPermission() async -> Bool {
        return await checkRecordingPermission()
    }
    
    public func startSystemAudioRecording() async throws {
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä¿å­˜å…ˆã§ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let filename = "SystemAudio_\(formatter.string(from: Date())).caf"
        let defaultURL = documentsPath.appendingPathComponent(filename)
        
        try await startSystemAudioRecording(to: defaultURL)
    }
    
    public func startSystemAudioRecording(to url: URL) async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        logger.info("Starting system audio recording to: \(url.path)")
        
        // ç”»é¢éŒ²ç”»æ¨©é™ãƒã‚§ãƒƒã‚¯  
        logger.info("ğŸ” Checking screen recording permissions...")
        let hasPermission = await checkRecordingPermission()
        logger.info("ğŸ” Permission check result: \(hasPermission)")
        
        if !hasPermission {
            let preflightResult = CGPreflightScreenCaptureAccess()
            logger.error("ğŸš« Screen recording permission denied. Preflight: \(preflightResult)")
            
            // ã‚ˆã‚Šè©³ç´°ãªæ¨©é™ãƒã‚§ãƒƒã‚¯
            if !preflightResult {
                logger.error("âš ï¸  Please grant Screen Recording permission in System Settings > Privacy & Security > Screen Recording")
            }
            
            throw RecordingError.permissionDenied("Screen Recording permission required. Check System Settings > Privacy & Security > Screen Recording")
        }
        
        logger.info("âœ… Screen recording permission confirmed")
        
        // æŒ‡å®šã•ã‚ŒãŸURLã‚’ä½¿ç”¨
        let recordingURL = url
        
        // ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        let parentDirectory = recordingURL.deletingLastPathComponent()
        try FileManager.default.createDirectory(at: parentDirectory, withIntermediateDirectories: true, attributes: nil)
        
        do {
            // ScreenCaptureKitã§ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            try await setupSystemAudioCapture(outputURL: recordingURL)
            
            // çŠ¶æ…‹ã‚’æ›´æ–°
            currentRecordingURL = recordingURL
            isRecording = true
            
            logger.info("ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: \(recordingURL.lastPathComponent)")
            logger.info("ä¿å­˜å ´æ‰€: \(recordingURL.path)")
        } catch {
            // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            stopRecording()
            if let error = error as? RecordingError {
                throw error
            } else {
                throw RecordingError.setupFailed(error.localizedDescription)
            }
        }
    }
    
    public func supportsSystemAudioCapture() -> Bool {
        return true // ScreenCaptureKit is available on macOS 13+
    }
    
    // MARK: - Private Methods
    
    private func setupAudioEngine(outputURL: URL) throws {
        // AVAudioEngineã®åˆæœŸåŒ–
        audioEngine = AVAudioEngine()
        guard let engine = audioEngine else {
            throw RecordingError.setupFailed("Failed to create audio engine")
        }
        
        let inputNode = engine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        logger.info("Input audio format: \(recordingFormat)")
        
        // å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        do {
            audioFile = try AVAudioFile(forWriting: outputURL, settings: recordingFormat.settings)
            logger.info("Audio file created with format: \(recordingFormat)")
            logger.info("Audio file path: \(outputURL.path)")
        } catch {
            throw RecordingError.setupFailed("Failed to create audio file: \(error.localizedDescription)")
        }
        
        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã‚¿ãƒƒãƒ—ã‚’è¨­å®š
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] (buffer: AVAudioPCMBuffer, time: AVAudioTime) in
            do {
                try self?.audioFile?.write(from: buffer)
            } catch {
                self?.logger.error("Failed to write audio buffer: \(error.localizedDescription)")
            }
        }
        
        logger.info("Audio engine setup completed")
    }
    
    private func setupSystemAudioCapture(outputURL: URL) async throws {
        do {
            logger.info("Getting shareable content...")
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            logger.info("Found \(content.displays.count) displays, \(content.applications.count) applications")
            
            guard let display = content.displays.first else {
                throw RecordingError.noDisplayFound
            }
            logger.info("Using display: \(display.displayID)")
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
            // å…¨ã¦ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®éŸ³å£°ã‚’å«ã‚ã‚‹
            let filter = SCContentFilter(display: display, excludingApplications: [], exceptingWindows: [])
            let configuration = SCStreamConfiguration()
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£è¨­å®š
            configuration.capturesAudio = true
            configuration.sampleRate = 44100
            configuration.channelCount = 2
            configuration.excludesCurrentProcessAudio = true // è‡ªåˆ†ã®ã‚¢ãƒ—ãƒªã®éŸ³å£°ã¯é™¤å¤–
            
            // ãƒ“ãƒ‡ã‚ªè¨­å®šã¯æœ€å°ã«ï¼ˆã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®ã¿ã§ã‚‚å¿…è¦ï¼‰
            configuration.width = 100
            configuration.height = 100
            configuration.minimumFrameInterval = CMTime(value: 1, timescale: 1)
            
            logger.info("Creating SCStream with system audio config...")
            logger.info("Audio capture enabled: \(configuration.capturesAudio)")
            logger.info("Sample rate: \(configuration.sampleRate), Channels: \(configuration.channelCount)")
            logger.info("Excludes current process audio: \(configuration.excludesCurrentProcessAudio)")
            
            captureSession = SCStream(filter: filter, configuration: configuration, delegate: self)
            
            guard let stream = captureSession else {
                logger.error("Failed to create SCStream object")
                throw RecordingError.screenCaptureKitError(NSError(domain: "MacRecode", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to create SCStream"]))
            }
            logger.info("SCStream created successfully")
            
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’å…ˆã«è¡Œã†
            try setupSystemAudioFile(outputURL: outputURL)
            logger.info("Audio file setup completed")
            
            logger.info("Adding audio stream output...")
            try stream.addStreamOutput(self, type: .audio, sampleHandlerQueue: recordingQueue)
            logger.info("Audio stream output added")
            
            // ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹å‰ã«å°‘ã—å¾…æ©Ÿ
            logger.info("Starting ScreenCaptureKit capture...")
            try await Task.sleep(nanoseconds: 100_000_000) // 100mså¾…æ©Ÿ
            try await stream.startCapture()
            
            logger.info("ScreenCaptureKit system audio capture started successfully")
        } catch {
            logger.error("ScreenCaptureKit setup failed: \(error.localizedDescription)")
            logger.error("Error details: \(error)")
            
            // å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            if let nsError = error as NSError? {
                logger.error("Error domain: \(nsError.domain)")
                logger.error("Error code: \(nsError.code)")
                logger.error("Error userInfo: \(nsError.userInfo)")
            }
            
            throw RecordingError.screenCaptureKitError(error)
        }
    }
    
    private func setupSystemAudioFile(outputURL: URL) throws {
        logger.info("ğŸ—‚ Creating system audio file: \(outputURL.lastPathComponent)")
        
        // ã‚ˆã‚Šäº’æ›æ€§ã®é«˜ã„CAFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 44100.0,
            AVNumberOfChannelsKey: 2,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsNonInterleaved: false
        ]
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèªã¨ä½œæˆ
        let parentDir = outputURL.deletingLastPathComponent()
        if !FileManager.default.fileExists(atPath: parentDir.path) {
            try FileManager.default.createDirectory(at: parentDir, withIntermediateDirectories: true, attributes: nil)
            logger.info("ğŸ“ Created directory: \(parentDir.path)")
        }
        
        // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
        if FileManager.default.fileExists(atPath: outputURL.path) {
            try FileManager.default.removeItem(at: outputURL)
            logger.info("ğŸ—‘ Removed existing file: \(outputURL.lastPathComponent)")
        }
        
        do {
            audioFile = try AVAudioFile(forWriting: outputURL, settings: settings)
            logger.info("âœ… System audio file created successfully: \(outputURL.path)")
        } catch {
            logger.error("âŒ Failed to create system audio file: \(error)")
            logger.error("   URL: \(outputURL.path)")
            logger.error("   Settings: \(settings)")
            throw RecordingError.setupFailed("Failed to create system audio file: \(error.localizedDescription)")
        }
        
        logger.info("System audio file setup completed")
    }
    
    private func setupMicrophoneAudioEngine(outputURL: URL) throws {
        logger.info("ğŸ¤ Creating microphone audio engine...")
        
        // ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³ç”¨ã®åˆ†é›¢ã•ã‚ŒãŸAVAudioEngineã‚’åˆæœŸåŒ–
        microphoneEngine = AVAudioEngine()
        guard let engine = microphoneEngine else {
            throw RecordingError.setupFailed("Failed to create microphone audio engine")
        }
        
        let inputNode = engine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        logger.info("Microphone input audio format: \(recordingFormat)")
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
        let parentDir = outputURL.deletingLastPathComponent()
        if !FileManager.default.fileExists(atPath: parentDir.path) {
            try FileManager.default.createDirectory(at: parentDir, withIntermediateDirectories: true, attributes: nil)
        }
        
        // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
        if FileManager.default.fileExists(atPath: outputURL.path) {
            try FileManager.default.removeItem(at: outputURL)
            logger.info("ğŸ—‘ Removed existing microphone file: \(outputURL.lastPathComponent)")
        }
        
        // ãƒã‚¤ã‚¯ç”¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆåˆ†é›¢ã•ã‚ŒãŸå¤‰æ•°ã‚’ä½¿ç”¨ï¼‰
        do {
            microphoneFile = try AVAudioFile(forWriting: outputURL, settings: recordingFormat.settings)
            logger.info("âœ… Microphone audio file created: \(outputURL.path)")
        } catch {
            logger.error("âŒ Failed to create microphone audio file: \(error)")
            throw RecordingError.setupFailed("Failed to create microphone audio file: \(error.localizedDescription)")
        }
        
        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã‚¿ãƒƒãƒ—ã‚’è¨­å®šï¼ˆåˆ†é›¢ã•ã‚ŒãŸå¤‰æ•°ã‚’ä½¿ç”¨ï¼‰
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] (buffer: AVAudioPCMBuffer, time: AVAudioTime) in
            do {
                try self?.microphoneFile?.write(from: buffer)
            } catch {
                self?.logger.error("Failed to write microphone audio buffer: \(error.localizedDescription)")
            }
        }
        
        logger.info("âœ… Microphone audio engine setup completed")
    }
    
    // MARK: - Mixed Recording Implementation
    
    private func startMixedRecording() async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        logger.info("Starting mixed recording (system audio + microphone)...")
        
        // ä¸¡æ–¹ã®æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯
        let hasSystemPermission = await checkRecordingPermission()
        guard hasSystemPermission else {
            throw RecordingError.permissionDenied("System audio permission required")
        }
        
        let hasMicPermission = await checkMicrophonePermission()
        guard hasMicPermission else {
            throw RecordingError.permissionDenied("Microphone permission required")
        }
        
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ç”Ÿæˆï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã«ä¿å­˜ã—ã¦ç¢ºèªã—ã‚„ã™ãã™ã‚‹ï¼‰
        let desktopPath = FileManager.default.urls(for: .desktopDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let timestamp = formatter.string(from: Date())
        
        let systemTempURL = desktopPath.appendingPathComponent("system_\(timestamp).caf")
        let micTempURL = desktopPath.appendingPathComponent("mic_\(timestamp).caf")
        let finalMixedURL = desktopPath.appendingPathComponent("Mixed_\(timestamp).caf")
        
        logger.info("ğŸ—‚ Mixed recording temp files:")
        logger.info("  System: \(systemTempURL.path)")
        logger.info("  Mic: \(micTempURL.path)")
        logger.info("  Final: \(finalMixedURL.path)")
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºä¿
        try FileManager.default.createDirectory(at: desktopPath, withIntermediateDirectories: true, attributes: nil)
        
        // ä¸¦è¡ŒéŒ²éŸ³ã‚’é–‹å§‹
        try await startDualRecording(systemURL: systemTempURL, micURL: micTempURL)
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        currentRecordingURL = finalMixedURL
        isRecording = true
        
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä¿å­˜ï¼ˆåœæ­¢æ™‚ã®ãƒŸãƒƒã‚¯ã‚¹å‡¦ç†ã®ãŸã‚ï¼‰
        self.systemTempURL = systemTempURL
        self.micTempURL = micTempURL
        self.finalMixedURL = finalMixedURL
        
        logger.info("Mixed recording started successfully")
    }
    
    private func startDualRecording(systemURL: URL, micURL: URL) async throws {
        logger.info("ğŸ”§ Setting up dual recording...")
        
        // é †æ¬¡ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆåŒæ™‚å®Ÿè¡Œã«ã‚ˆã‚‹ç«¶åˆã‚’é¿ã‘ã‚‹ï¼‰
        logger.info("ğŸ“» Setting up system audio capture...")
        try await setupSystemAudioCapture(outputURL: systemURL)
        logger.info("âœ… System audio capture setup complete")
        
        // å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒã‚¤ã‚¯ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        try await Task.sleep(nanoseconds: 200_000_000) // 200mså¾…æ©Ÿ
        
        logger.info("ğŸ¤ Setting up microphone recording...")
        try setupMicrophoneAudioEngine(outputURL: micURL)
        logger.info("âœ… Microphone recording setup complete")
        
        // ãƒã‚¤ã‚¯éŒ²éŸ³ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‹å§‹ï¼ˆåˆ†é›¢ã•ã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ï¼‰
        logger.info("ğŸš€ Starting microphone audio engine...")
        try microphoneEngine?.start()
        logger.info("âœ… Dual recording setup completed successfully")
    }
    
    public func stopMixedRecording() async throws {
        guard isRecording else { return }
        
        logger.info("Stopping mixed recording...")
        
        // ãƒã‚¤ã‚¯éŒ²éŸ³ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢ï¼ˆåˆ†é›¢ã•ã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³ï¼‰
        if let micEngine = microphoneEngine, micEngine.isRunning {
            micEngine.stop()
            micEngine.inputNode.removeTap(onBus: 0)
            logger.info("âœ… Microphone engine stopped")
        }
        
        // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢
        Task {
            do {
                try await captureSession?.stopCapture()
                self.logger.info("âœ… System audio capture stopped")
            } catch {
                self.logger.error("Failed to stop capture session: \(error)")
            }
        }
        
        // ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        captureSession = nil
        audioFile = nil
        microphoneFile = nil
        microphoneEngine = nil
        
        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŸãƒƒã‚¯ã‚¹
        guard let systemURL = systemTempURL,
              let micURL = micTempURL,
              let outputURL = finalMixedURL else {
            throw RecordingError.setupFailed("Missing temp file URLs")
        }
        
        try await mixAudioFiles(systemURL: systemURL, micURL: micURL, outputURL: outputURL)
        
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanupTempFiles(systemURL: systemURL, micURL: micURL)
        
        // çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        isRecording = false
        self.systemTempURL = nil
        self.micTempURL = nil
        self.finalMixedURL = nil
        
        logger.info("Mixed recording completed and mixed")
    }
    
    private func mixAudioFiles(systemURL: URL, micURL: URL, outputURL: URL) async throws {
        logger.info("Mixing audio files...")
        
        // AVAudioEngineã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒŸã‚­ã‚·ãƒ³ã‚°
        let engine = AVAudioEngine()
        let mixer = engine.mainMixerNode
        
        // ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒãƒ¼ãƒ‰ã‚’ä½œæˆ
        let systemPlayer = AVAudioPlayerNode()
        let micPlayer = AVAudioPlayerNode()
        
        engine.attach(systemPlayer)
        engine.attach(micPlayer)
        
        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        guard FileManager.default.fileExists(atPath: systemURL.path) else {
            throw RecordingError.setupFailed("System audio file not found")
        }
        
        guard FileManager.default.fileExists(atPath: micURL.path) else {
            throw RecordingError.setupFailed("Microphone file not found")
        }
        
        let systemFile = try AVAudioFile(forReading: systemURL)
        let micFile = try AVAudioFile(forReading: micURL)
        
        // å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆçµ±ä¸€ï¼‰
        guard let outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: 44100,
            channels: 2,
            interleaved: false
        ) else {
            throw RecordingError.setupFailed("Failed to create output format")
        }
        
        // ãƒŸã‚­ã‚µãƒ¼ã«æ¥ç¶š
        engine.connect(systemPlayer, to: mixer, format: outputFormat)
        engine.connect(micPlayer, to: mixer, format: outputFormat)
        
        // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        let outputFile = try AVAudioFile(forWriting: outputURL, settings: outputFormat.settings)
        
        // ç°¡æ˜“ãƒŸã‚­ã‚·ãƒ³ã‚°: ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ãƒã‚¤ã‚¯éŸ³å£°ã‚’è¿½åŠ 
        try await performSimpleMixing(
            systemFile: systemFile,
            micFile: micFile,
            outputFile: outputFile,
            outputFormat: outputFormat
        )
        
        logger.info("Audio mixing completed")
    }
    
    private func performSimpleMixing(
        systemFile: AVAudioFile,
        micFile: AVAudioFile,
        outputFile: AVAudioFile,
        outputFormat: AVAudioFormat
    ) async throws {
        
        let maxFrames = max(systemFile.length, micFile.length)
        let bufferSize: AVAudioFrameCount = 4096
        
        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆäº’æ›æ€§ãƒã‚§ãƒƒã‚¯
        guard AVAudioConverter(from: systemFile.processingFormat, to: outputFormat) != nil else {
            throw RecordingError.setupFailed("Failed to create system audio converter")
        }
        
        guard AVAudioConverter(from: micFile.processingFormat, to: outputFormat) != nil else {
            throw RecordingError.setupFailed("Failed to create microphone converter")
        }
        
        var framesProcessed: AVAudioFramePosition = 0
        
        while framesProcessed < maxFrames {
            let framesToProcess = min(bufferSize, AVAudioFrameCount(maxFrames - framesProcessed))
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒãƒƒãƒ•ã‚¡
            let systemBuffer = AVAudioPCMBuffer(pcmFormat: systemFile.processingFormat, frameCapacity: framesToProcess) ?? AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: framesToProcess)!
            let micBuffer = AVAudioPCMBuffer(pcmFormat: micFile.processingFormat, frameCapacity: framesToProcess) ?? AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: framesToProcess)!
            
            // å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡
            guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: framesToProcess) else {
                throw RecordingError.setupFailed("Failed to create output buffer")
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            systemFile.framePosition = framesProcessed
            micFile.framePosition = framesProcessed
            
            var actualSystemFrames: AVAudioFrameCount = 0
            var actualMicFrames: AVAudioFrameCount = 0
            
            if framesProcessed < systemFile.length {
                try systemFile.read(into: systemBuffer, frameCount: framesToProcess)
                actualSystemFrames = systemBuffer.frameLength
            }
            
            if framesProcessed < micFile.length {
                try micFile.read(into: micBuffer, frameCount: framesToProcess)
                actualMicFrames = micBuffer.frameLength
            }
            
            // ç°¡æ˜“ãƒŸã‚­ã‚·ãƒ³ã‚°: ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒã‚¤ã‚¯ã‚’è¿½åŠ 
            outputBuffer.frameLength = max(actualSystemFrames, actualMicFrames)
            
            if let systemFloatData = systemBuffer.floatChannelData,
               let micFloatData = micBuffer.floatChannelData,
               let outputFloatData = outputBuffer.floatChannelData {
                
                for channel in 0..<Int(outputFormat.channelCount) {
                    for frame in 0..<Int(outputBuffer.frameLength) {
                        var mixedSample: Float = 0.0
                        
                        // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ï¼ˆ75%ã®éŸ³é‡ï¼‰
                        if channel < systemBuffer.format.channelCount && frame < actualSystemFrames {
                            mixedSample += systemFloatData[channel][frame] * 0.75
                        }
                        
                        // ãƒã‚¤ã‚¯éŸ³å£°ï¼ˆ50%ã®éŸ³é‡ï¼‰
                        if channel < micBuffer.format.channelCount && frame < actualMicFrames {
                            mixedSample += micFloatData[min(channel, Int(micBuffer.format.channelCount)-1)][frame] * 0.5
                        }
                        
                        // ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢
                        outputFloatData[channel][frame] = max(-1.0, min(1.0, mixedSample))
                    }
                }
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            try outputFile.write(from: outputBuffer)
            
            framesProcessed += AVAudioFramePosition(outputBuffer.frameLength)
        }
    }
    
    private func cleanupTempFiles(systemURL: URL, micURL: URL) {
        do {
            if FileManager.default.fileExists(atPath: systemURL.path) {
                try FileManager.default.removeItem(at: systemURL)
                logger.info("Cleaned up system audio temp file")
            }
            
            if FileManager.default.fileExists(atPath: micURL.path) {
                try FileManager.default.removeItem(at: micURL)
                logger.info("Cleaned up microphone temp file")
            }
        } catch {
            logger.error("Failed to cleanup temp files: \(error)")
        }
    }
}

// MARK: - SCStreamOutput Protocol
extension SystemAudioRecorder {
    nonisolated public func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard type == .audio else { 
            // ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã¯ç„¡è¦–
            return 
        }
        
        // éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã®å—ä¿¡ã‚’ãƒ­ã‚°ï¼ˆ1å›ã®ã¿å‡ºåŠ›ï¼‰
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        if frameCount > 0 {
            // æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ­ã‚°ï¼ˆã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãŒæµã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
            Task { @MainActor in
                if self.lastAudioLogTime == nil {
                    self.logger.info("ğŸ“» System audio capture active: \(frameCount) frames received")
                    self.lastAudioLogTime = Date()
                }
            }
        }
        
        recordingQueue.async { [weak self] in
            guard let self = self else { return }
            
            // CMSampleBufferã‚’AVAudioPCMBufferã«å¤‰æ›ï¼ˆåŒæœŸçš„ã«å®Ÿè¡Œï¼‰
            guard let audioBuffer = self.createAudioBuffer(from: sampleBuffer) else {
                Task { @MainActor in
                    self.logger.error("Failed to create audio buffer from sample buffer")
                }
                return
            }
            
            Task { @MainActor in
                guard self.isRecording else { return }
                
                // ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
                do {
                    try self.audioFile?.write(from: audioBuffer)
                } catch {
                    self.logger.error("Failed to write system audio buffer: \(error.localizedDescription)")
                }
            }
        }
    }
    
    nonisolated private func createAudioBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer) else {
            return nil
        }
        
        let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription)
        guard let description = audioStreamBasicDescription else {
            return nil
        }
        
        var streamDescription = description.pointee
        guard let format = AVAudioFormat(streamDescription: &streamDescription) else {
            return nil
        }
        
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return nil
        }
        
        buffer.frameLength = AVAudioFrameCount(frameCount)
        
        guard let audioBlockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else {
            return nil
        }
        
        var dataPointer: UnsafeMutablePointer<Int8>?
        var length: Int = 0
        
        let status = CMBlockBufferGetDataPointer(audioBlockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &length, dataPointerOut: &dataPointer)
        
        guard status == noErr, let pointer = dataPointer else {
            return nil
        }
        
        memcpy(buffer.audioBufferList.pointee.mBuffers.mData, pointer, length)
        
        return buffer
    }
}