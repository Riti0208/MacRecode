import Foundation
import AVFoundation
import ScreenCaptureKit
import OSLog

public enum RecordingMode {
    case microphoneOnly
    case systemAudioOnly
    case mixedRecording
    case catapSynchronized // CATap API ã«ã‚ˆã‚‹åŒæœŸéŒ²éŸ³
}

public enum RecordingError: LocalizedError {
    case permissionDenied(String)
    case noDisplayFound
    case setupFailed(String)
    case recordingInProgress
    case screenCaptureKitError(Error)
    case mixingEngineFailed(String)
    case audioFormatError(String)
    
    public var errorDescription: String? {
        switch self {
        case .permissionDenied(let details):
            return "ç”»é¢åéŒ²ã®æ¨©é™ãŒå¿…è¦ã§ã™ã€‚è©³ç´°: \(details)\n\nã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ > ç”»é¢åéŒ² ã§è¨±å¯ã—ã¦ãã ã•ã„ã€‚"
        case .noDisplayFound:
            return "éŒ²éŸ³å¯èƒ½ãªãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        case .setupFailed(let details):
            return "éŒ²éŸ³ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: \(details)"
        case .recordingInProgress:
            return "éŒ²éŸ³ãŒæ—¢ã«é–‹å§‹ã•ã‚Œã¦ã„ã¾ã™"
        case .screenCaptureKitError(let error):
            return "ScreenCaptureKitã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
        case .mixingEngineFailed(let details):
            return "ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚¨ãƒ©ãƒ¼: \(details)"
        case .audioFormatError(let details):
            return "éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: \(details)"
        }
    }
}

// MARK: - Memory-based Audio Buffer Manager
@MainActor
public class AudioBufferManager: ObservableObject {
    private var systemAudioBuffers: [AVAudioPCMBuffer] = []
    private var microphoneBuffers: [AVAudioPCMBuffer] = []
    private let bufferQueue = DispatchQueue(label: "AudioBufferQueue", qos: .userInitiated)
    private let logger = Logger(subsystem: "com.example.MacRecode", category: "AudioBufferManager")
    
    public init() {}
    
    public func addSystemAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        bufferQueue.async { [weak self] in
            guard let self = self else { return }
            // ãƒãƒƒãƒ•ã‚¡ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ä¿å­˜
            if let copy = self.copyBuffer(buffer) {
                self.systemAudioBuffers.append(copy)
            }
        }
    }
    
    public func addMicrophoneBuffer(_ buffer: AVAudioPCMBuffer) {
        bufferQueue.async { [weak self] in
            guard let self = self else { return }
            // ãƒãƒƒãƒ•ã‚¡ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ä¿å­˜
            if let copy = self.copyBuffer(buffer) {
                self.microphoneBuffers.append(copy)
            }
        }
    }
    
    public func createMixedAudioFile(to outputURL: URL) async throws {
        logger.info("ğŸµ Creating mixed audio file with \(self.systemAudioBuffers.count) system buffers and \(self.microphoneBuffers.count) microphone buffers")
        
        try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
            bufferQueue.async { [weak self] in
                guard let self = self else {
                    continuation.resume(throwing: RecordingError.setupFailed("AudioBufferManager was deallocated"))
                    return
                }
                
                do {
                    try self.performMixing(to: outputURL)
                    continuation.resume()
                } catch {
                    continuation.resume(throwing: error)
                }
            }
        }
    }
    
    private func performMixing(to outputURL: URL) throws {
        // å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¨­å®šï¼ˆ44.1kHz, 2ch, 16bitï¼‰
        guard let outputFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 44100,
            channels: 2,
            interleaved: false
        ) else {
            throw RecordingError.setupFailed("Failed to create output format")
        }
        
        // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        let outputFile = try AVAudioFile(forWriting: outputURL, settings: outputFormat.settings)
        
        // ãƒãƒƒãƒ•ã‚¡ã®é•·ã•ã‚’èª¿æ•´ã—ã¦ãƒŸãƒƒã‚¯ã‚¹
        let maxBuffers = max(self.systemAudioBuffers.count, self.microphoneBuffers.count)
        
        for i in 0..<maxBuffers {
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã¨ãƒã‚¤ã‚¯ã®ãƒãƒƒãƒ•ã‚¡ã‚’å–å¾—
            let systemBuffer = i < self.systemAudioBuffers.count ? self.systemAudioBuffers[i] : nil
            let micBuffer = i < self.microphoneBuffers.count ? self.microphoneBuffers[i] : nil
            
            // ãƒŸãƒƒã‚¯ã‚¹ç”¨ã®å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
            let frameCount = max(systemBuffer?.frameLength ?? 0, micBuffer?.frameLength ?? 0)
            guard frameCount > 0,
                  let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: frameCount) else {
                continue
            }
            
            outputBuffer.frameLength = frameCount
            
            // ç°¡å˜ãªãƒŸãƒƒã‚¯ã‚¹å‡¦ç†ï¼ˆã‚·ã‚¹ãƒ†ãƒ éŸ³å£°75% + ãƒã‚¤ã‚¯50%ï¼‰
            if let systemData = systemBuffer?.floatChannelData?[0],
               let outputData = outputBuffer.floatChannelData?[0] {
                for frameIndex in 0..<Int(frameCount) {
                    if frameIndex < Int(systemBuffer?.frameLength ?? 0) {
                        outputData[frameIndex] = systemData[frameIndex] * 0.75
                    }
                }
            }
            
            if let micData = micBuffer?.floatChannelData?[0],
               let outputData = outputBuffer.floatChannelData?[0] {
                for frameIndex in 0..<Int(frameCount) {
                    if frameIndex < Int(micBuffer?.frameLength ?? 0) {
                        outputData[frameIndex] += micData[frameIndex] * 0.5
                    }
                }
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            try outputFile.write(from: outputBuffer)
        }
        
        logger.info("âœ… Mixed audio file created successfully: \(outputURL.lastPathComponent)")
    }
    
    private func copyBuffer(_ buffer: AVAudioPCMBuffer) -> AVAudioPCMBuffer? {
        guard let copy = AVAudioPCMBuffer(pcmFormat: buffer.format, frameCapacity: buffer.frameCapacity) else {
            return nil
        }
        
        copy.frameLength = buffer.frameLength
        
        // ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
        if let sourceData = buffer.floatChannelData,
           let destData = copy.floatChannelData {
            for channel in 0..<Int(buffer.format.channelCount) {
                memcpy(destData[channel], sourceData[channel], Int(buffer.frameLength) * MemoryLayout<Float>.size)
            }
        }
        
        return copy
    }
    
    public func clearBuffers() {
        bufferQueue.async { [weak self] in
            guard let self = self else { return }
            self.systemAudioBuffers.removeAll()
            self.microphoneBuffers.removeAll()
        }
    }
}

@MainActor
public class SystemAudioRecorder: NSObject, ObservableObject, SCStreamDelegate, SCStreamOutput {
    @Published public private(set) var isRecording = false
    @Published public private(set) var currentRecordingURL: URL?
    @Published public private(set) var recordingMode: RecordingMode = .systemAudioOnly
    
    private var captureSession: SCStream?
    private var audioEngine: AVAudioEngine?
    private var audioFile: AVAudioFile?
    
    // ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³ç”¨ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    private var bufferManager: AudioBufferManager?
    private var microphoneEngine: AVAudioEngine?
    private var isBufferRecording = false
    
    private let logger = Logger(subsystem: "com.example.MacRecode", category: "SystemAudioRecorder")
    private let recordingQueue = DispatchQueue(label: "com.example.MacRecode.recording", qos: .userInitiated)
    private var lastAudioLogTime: Date?
    
    // Mixed recording properties
    private var mixingEngine: AVAudioEngine?
    private var mixerNode: AVAudioMixerNode?
    private var systemAudioPlayerNode: AVAudioPlayerNode?
    private var mixedAudioFile: AVAudioFile?
    private var systemAudioBuffer: AVAudioPCMBuffer?
    
    public override init() {
        super.init()
    }
    
    // MARK: - Recording Mode Management
    
    public func setRecordingMode(_ mode: RecordingMode) {
        guard !isRecording else { return }
        recordingMode = mode
    }
    
    // MARK: - Mixed Recording Integration
    
    public func startRecordingWithMode() async throws {
        switch recordingMode {
        case .systemAudioOnly:
            try await startSystemAudioRecording()
        case .microphoneOnly:
            try await startMicrophoneRecording()
        case .mixedRecording:
            // çœŸã®ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³: ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã¨ãƒã‚¤ã‚¯ã‚’ä¸¦è¡ŒéŒ²éŸ³
            logger.info("Mixed recording selected - starting dual audio capture")
            try await startMixedRecording()
        case .catapSynchronized:
            // CATap APIçµ±åˆéŒ²éŸ³ã¯ContentViewã§ç›´æ¥å‡¦ç†ã•ã‚Œã‚‹
            logger.info("CATap synchronized recording mode selected - handled by ContentView")
            throw RecordingError.setupFailed("CATap recording should be handled directly by ContentView")
        }
    }
    
    // MARK: - Microphone Recording Methods
    
    public func checkMicrophonePermission() async -> Bool {
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        logger.info("Current microphone permission status: \(status.rawValue)")
        
        switch status {
        case .authorized:
            logger.info("Microphone permission already granted")
            return true
        case .notDetermined:
            logger.info("Requesting microphone permission...")
            let granted = await AVCaptureDevice.requestAccess(for: .audio)
            logger.info("Microphone permission granted: \(granted)")
            return granted
        case .denied, .restricted:
            logger.error("Microphone permission denied or restricted")
            return false
        @unknown default:
            logger.error("Unknown microphone permission status")
            return false
        }
    }
    
    public func startMicrophoneRecording() async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        // ãƒã‚¤ã‚¯æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯
        let hasPermission = await checkMicrophonePermission()
        guard hasPermission else {
            throw RecordingError.permissionDenied("Microphone permission required")
        }
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ç”Ÿæˆï¼ˆDocumentsãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼‰
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let fileName = "Microphone_\(formatter.string(from: Date())).caf"
        let recordingURL = documentsPath.appendingPathComponent(fileName)
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        try FileManager.default.createDirectory(at: documentsPath, withIntermediateDirectories: true, attributes: nil)
        
        do {
            // ãƒã‚¤ã‚¯éŒ²éŸ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            try setupMicrophoneAudioEngine(outputURL: recordingURL)
            
            // éŒ²éŸ³é–‹å§‹
            try audioEngine?.start()
            
            // çŠ¶æ…‹ã‚’æ›´æ–°
            currentRecordingURL = recordingURL
            isRecording = true
            
            logger.info("ãƒã‚¤ã‚¯éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: \(fileName)")
            logger.info("ä¿å­˜å ´æ‰€: \(recordingURL.path)")
        } catch {
            // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            stopRecording()
            if let error = error as? RecordingError {
                throw error
            } else {
                throw RecordingError.setupFailed(error.localizedDescription)
            }
        }
    }
    
    public func checkRecordingPermission() async -> Bool {
        // ã¾ãšãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆãƒã‚§ãƒƒã‚¯
        let canRecord = CGPreflightScreenCaptureAccess()
        logger.info("Screen capture preflight check: \(canRecord)")
        
        if !canRecord {
            // æ¨©é™ãŒãªã„å ´åˆã¯è¦æ±‚
            logger.info("Requesting screen capture access...")
            let granted = CGRequestScreenCaptureAccess()
            logger.info("Screen capture access granted: \(granted)")
            
            // æ¨©é™è¦æ±‚å¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†åº¦ç¢ºèª
            if granted {
                try? await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’å¾…æ©Ÿ
                let recheckResult = CGPreflightScreenCaptureAccess()
                logger.info("Screen capture recheck after grant: \(recheckResult)")
                return recheckResult
            }
            return granted
        }
        
        // æ¨©é™ãŒã‚ã£ã¦ã‚‚ã€å®Ÿéš›ã«ScreenCaptureKitãŒä½¿ãˆã‚‹ã‹ãƒ†ã‚¹ãƒˆ
        do {
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            logger.info("ScreenCaptureKit test successful: \(content.displays.count) displays found")
            return !content.displays.isEmpty
        } catch {
            logger.error("ScreenCaptureKit test failed: \(error.localizedDescription)")
            return false
        }
    }
    
    // MARK: - System Audio Recording Methods
    
    public func checkSystemAudioPermission() async -> Bool {
        return await checkRecordingPermission()
    }
    
    public func startSystemAudioRecording() async throws {
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä¿å­˜å…ˆã§ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let filename = "SystemAudio_\(formatter.string(from: Date())).caf"
        let defaultURL = documentsPath.appendingPathComponent(filename)
        
        try await startSystemAudioRecording(to: defaultURL)
    }
    
    public func startSystemAudioRecording(to url: URL) async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        logger.info("Starting system audio recording to: \(url.path)")
        
        // ç”»é¢éŒ²ç”»æ¨©é™ãƒã‚§ãƒƒã‚¯  
        logger.info("ğŸ” Checking screen recording permissions...")
        let hasPermission = await checkRecordingPermission()
        logger.info("ğŸ” Permission check result: \(hasPermission)")
        
        if !hasPermission {
            let preflightResult = CGPreflightScreenCaptureAccess()
            logger.error("ğŸš« Screen recording permission denied. Preflight: \(preflightResult)")
            
            // ã‚ˆã‚Šè©³ç´°ãªæ¨©é™ãƒã‚§ãƒƒã‚¯
            if !preflightResult {
                logger.error("âš ï¸  Please grant Screen Recording permission in System Settings > Privacy & Security > Screen Recording")
            }
            
            throw RecordingError.permissionDenied("Screen Recording permission required. Check System Settings > Privacy & Security > Screen Recording")
        }
        
        logger.info("âœ… Screen recording permission confirmed")
        
        // æŒ‡å®šã•ã‚ŒãŸURLã‚’ä½¿ç”¨
        let recordingURL = url
        
        // ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        let parentDirectory = recordingURL.deletingLastPathComponent()
        try FileManager.default.createDirectory(at: parentDirectory, withIntermediateDirectories: true, attributes: nil)
        
        do {
            // ScreenCaptureKitã§ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            try await setupSystemAudioCapture(outputURL: recordingURL)
            
            // çŠ¶æ…‹ã‚’æ›´æ–°
            currentRecordingURL = recordingURL
            isRecording = true
            
            logger.info("ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: \(recordingURL.lastPathComponent)")
            logger.info("ä¿å­˜å ´æ‰€: \(recordingURL.path)")
        } catch {
            // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            stopRecording()
            if let error = error as? RecordingError {
                throw error
            } else {
                throw RecordingError.setupFailed(error.localizedDescription)
            }
        }
    }
    
    public func supportsSystemAudioCapture() -> Bool {
        return true // ScreenCaptureKit is available on macOS 13+
    }
    
    public func stopRecording() {
        guard isRecording else { return }
        
        logger.info("éŒ²éŸ³ã‚’åœæ­¢ä¸­...")
        
        // é€šå¸¸ã®éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if let engine = audioEngine, engine.isRunning {
            engine.stop()
            engine.inputNode.removeTap(onBus: 0)  // ã‚¿ãƒƒãƒ—ã‚’å‰Šé™¤
            logger.info("Audio engine stopped")
        }
        
        // ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if let mixEngine = mixingEngine, mixEngine.isRunning {
            mixEngine.stop() 
            mixerNode?.removeTap(onBus: 0) // ãƒŸã‚­ã‚µãƒ¼ã®ã‚¿ãƒƒãƒ—ã‚’å‰Šé™¤
            logger.info("Mixing engine stopped")
        }
        
        // ãƒã‚¤ã‚¯éŒ²éŸ³ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if let micEngine = microphoneEngine, micEngine.isRunning {
            micEngine.stop()
            micEngine.inputNode.removeTap(onBus: 0)
            logger.info("Microphone engine stopped")
        }
        
        // ScreenCaptureKit ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åœæ­¢
        Task {
            do {
                try await captureSession?.stopCapture()
            } catch {
                self.logger.error("Failed to stop capture session: \(error)")
            }
        }
        captureSession = nil
        
        // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        audioFile = nil
        mixedAudioFile = nil
        
        // ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        audioEngine = nil
        mixingEngine = nil
        mixerNode = nil
        systemAudioPlayerNode = nil
        microphoneEngine = nil
        bufferManager = nil
        isBufferRecording = false
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        isRecording = false
        
        if let url = currentRecordingURL {
            logger.info("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«: \(url.lastPathComponent)")
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
            do {
                let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
                if let fileSize = attributes[.size] as? Int64 {
                    logger.info("ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(fileSize) bytes")
                }
            } catch {
                logger.error("Failed to get file size: \(error.localizedDescription)")
            }
        }
    }
    
    // MARK: - Mixed Recording Methods
    
    public func startMixedRecording() async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let fileName = "MixedRecording_\(Date().timeIntervalSince1970).caf"
        let recordingURL = documentsPath.appendingPathComponent(fileName)
        
        // ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã‚’ç¢ºèª
        do {
            try FileManager.default.createDirectory(at: documentsPath, withIntermediateDirectories: true, attributes: nil)
        } catch {
            throw RecordingError.setupFailed("éŒ²éŸ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: \(error.localizedDescription)")
        }
        
        try await setupMixedRecording()
        try setupMixedAudioFile(outputURL: recordingURL)
        
        // éŒ²éŸ³é–‹å§‹
        try mixingEngine?.start()
        
        currentRecordingURL = recordingURL
        isRecording = true
        
        logger.info("ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ: \(fileName)")
    }
    
    public func setupMixedRecording() async throws {
        // AVAudioEngineã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        mixingEngine = AVAudioEngine()
        guard let engine = mixingEngine else {
            throw RecordingError.setupFailed("AVAudioEngineã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        }
        
        // ãƒŸã‚­ã‚µãƒ¼ãƒãƒ¼ãƒ‰ã®ä½œæˆã¨æ¥ç¶š
        mixerNode = AVAudioMixerNode()
        guard let mixer = mixerNode else {
            throw RecordingError.setupFailed("AVAudioMixerNodeã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        }
        
        let mixedFormat = getMixedRecordingFormat()
        
        do {
            engine.attach(mixer)
            engine.connect(mixer, to: engine.outputNode, format: mixedFormat)
            
            // ãƒã‚¤ã‚¯å…¥åŠ›ã‚’æ¥ç¶š
            let inputNode = engine.inputNode
            let inputFormat = inputNode.inputFormat(forBus: 0)
            
            // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆäº’æ›æ€§ãƒã‚§ãƒƒã‚¯
            guard inputFormat.sampleRate > 0 && inputFormat.channelCount > 0 else {
                throw RecordingError.setupFailed("ç„¡åŠ¹ãªãƒã‚¤ã‚¯å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ")
            }
            
            engine.connect(inputNode, to: mixer, format: inputFormat)
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒãƒ¼ãƒ‰ã®ä½œæˆã¨æ¥ç¶š
            systemAudioPlayerNode = AVAudioPlayerNode()
            guard let playerNode = systemAudioPlayerNode else {
                throw RecordingError.setupFailed("AVAudioPlayerNodeã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            }
            
            engine.attach(playerNode)
            engine.connect(playerNode, to: mixer, format: mixedFormat)
            
            logger.info("ãƒŸãƒƒã‚¯ã‚¹éŒ²éŸ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸ")
            logger.info("å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: \(inputFormat)")
            logger.info("ãƒŸãƒƒã‚¯ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: \(mixedFormat)")
            
        } catch {
            // ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            mixingEngine = nil
            mixerNode = nil
            systemAudioPlayerNode = nil
            
            if let recordingError = error as? RecordingError {
                throw recordingError
            } else {
                throw RecordingError.setupFailed("ãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)")
            }
        }
    }
    
    public func startMixedRecordingWithSync() async throws -> AVAudioTime? {
        try await startMixedRecording()
        return mixingEngine?.outputNode.lastRenderTime
    }
    
    public func getMixedRecordingFormat() -> AVAudioFormat {
        return AVAudioFormat(standardFormatWithSampleRate: 44100.0, channels: 2) ?? 
               AVAudioFormat(standardFormatWithSampleRate: 44100.0, channels: 1)!
    }
    
    public func hasMixerNodeConfigured() -> Bool {
        return mixerNode != nil
    }
    
    public func hasSystemAudioPlayerNodeConnected() -> Bool {
        return systemAudioPlayerNode != nil
    }
    
    public func hasMicrophoneInputConnected() -> Bool {
        return mixingEngine?.inputNode != nil
    }
    
    public func isSystemAudioSynchronized() -> Bool {
        // æœ€å°å®Ÿè£…: å¸¸ã«trueã‚’è¿”ã™
        return true
    }
    
    public func isMicrophoneSynchronized() -> Bool {
        // æœ€å°å®Ÿè£…: å¸¸ã«trueã‚’è¿”ã™
        return true
    }
    
    private func setupMixedAudioFile(outputURL: URL) throws {
        let format = getMixedRecordingFormat()
        mixedAudioFile = try AVAudioFile(forWriting: outputURL, settings: format.settings)
        
        // ãƒŸã‚­ã‚µãƒ¼ã‹ã‚‰ã®å‡ºåŠ›ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«éŒ²éŸ³ã™ã‚‹ã‚¿ãƒƒãƒ—ã‚’è¨­å®š
        mixerNode?.installTap(onBus: 0, bufferSize: 1024, format: format) { [weak self] buffer, time in
            do {
                try self?.mixedAudioFile?.write(from: buffer)
            } catch {
                self?.logger.error("Failed to write mixed audio buffer: \(error.localizedDescription)")
            }
        }
        
        logger.info("Mixed audio file setup completed: \(outputURL.path)")
    }
    
    // MARK: - Private Methods
    
    // MARK: - Mixed Recording Implementation (Memory Buffer Approach)
    
    private func startMixedMemoryRecording() async throws {
        guard !isRecording else {
            throw RecordingError.recordingInProgress
        }
        
        logger.info("ğŸµ Starting mixed recording with memory buffer approach...")
        
        // ä¸¡æ–¹ã®æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯
        let hasSystemPermission = await checkRecordingPermission()
        guard hasSystemPermission else {
            throw RecordingError.permissionDenied("System audio permission required")
        }
        
        let hasMicPermission = await checkMicrophonePermission()
        guard hasMicPermission else {
            throw RecordingError.permissionDenied("Microphone permission required")
        }
        
        // ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
        bufferManager = AudioBufferManager()
        
        // æœ€çµ‚å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’ç”Ÿæˆ
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let timestamp = formatter.string(from: Date())
        let finalMixedURL = documentsPath.appendingPathComponent("Mixed_\(timestamp).caf")
        
        logger.info("ğŸ—‚ Mixed recording output: \(finalMixedURL.path)")
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºä¿
        try FileManager.default.createDirectory(at: documentsPath, withIntermediateDirectories: true, attributes: nil)
        
        // ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡éŒ²éŸ³ã‚’é–‹å§‹
        try await startMemoryBufferRecording()
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        currentRecordingURL = finalMixedURL
        isRecording = true
        isBufferRecording = true
        
        logger.info("âœ… Mixed recording started successfully with memory buffers")
    }
    
    private func startMemoryBufferRecording() async throws {
        logger.info("ğŸ”§ Setting up memory buffer recording...")
        
        // ãƒã‚¤ã‚¯éŒ²éŸ³ç”¨ã®AVAudioEngineã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        logger.info("ğŸ¤ Setting up microphone recording...")
        try setupMicrophoneForBufferRecording()
        logger.info("âœ… Microphone recording setup complete")
        
        // ãƒã‚¤ã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‹å§‹
        logger.info("ğŸš€ Starting microphone audio engine...")
        try microphoneEngine?.start()
        logger.info("âœ… Microphone engine started")
        
        // å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚’é–‹å§‹
        try await Task.sleep(nanoseconds: 500_000_000) // 500mså¾…æ©Ÿ
        
        logger.info("ğŸ“» Setting up system audio capture...")
        try await setupSystemAudioForBufferRecording()
        logger.info("âœ… System audio capture setup complete")
        
        logger.info("âœ… Memory buffer recording setup completed successfully")
    }
    
    public func stopMixedRecording() async throws {
        guard isRecording && isBufferRecording else { return }
        
        logger.info("ğŸš« Stopping mixed recording...")
        
        // ãƒã‚¤ã‚¯éŒ²éŸ³ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if let micEngine = microphoneEngine, micEngine.isRunning {
            micEngine.stop()
            micEngine.inputNode.removeTap(onBus: 0)
            logger.info("âœ… Microphone engine stopped")
        }
        
        // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢
        Task {
            do {
                try await captureSession?.stopCapture()
                self.logger.info("âœ… System audio capture stopped")
            } catch {
                self.logger.error("Failed to stop capture session: \(error)")
            }
        }
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        isBufferRecording = false
        
        // ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã‹ã‚‰ãƒŸãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        guard let bufferManager = self.bufferManager,
              let outputURL = currentRecordingURL else {
            throw RecordingError.setupFailed("Buffer manager or output URL missing")
        }
        
        logger.info("ğŸµ Creating mixed audio file from memory buffers...")
        try await bufferManager.createMixedAudioFile(to: outputURL)
        
        // ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        captureSession = nil
        microphoneEngine = nil
        self.bufferManager = nil
        
        // çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        isRecording = false
        
        logger.info("âœ… Mixed recording completed successfully")
    }
    
    // MARK: - Setup Methods for Buffer Recording
    
    private func setupMicrophoneForBufferRecording() throws {
        logger.info("ğŸ¤ Creating microphone for buffer recording...")
        
        // AVAudioEngineã‚’åˆæœŸåŒ–
        microphoneEngine = AVAudioEngine()
        guard let engine = microphoneEngine else {
            throw RecordingError.setupFailed("Failed to create microphone audio engine")
        }
        
        let inputNode = engine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        logger.info("Microphone input audio format: \(recordingFormat)")
        
        // ãƒã‚¤ã‚¯ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã«é€ã‚‹ã‚¿ãƒƒãƒ—ã‚’è¨­å®š
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] (buffer: AVAudioPCMBuffer, time: AVAudioTime) in
            Task { @MainActor in
                guard let self = self, self.isBufferRecording else { return }
                self.bufferManager?.addMicrophoneBuffer(buffer)
            }
        }
        
        logger.info("âœ… Microphone buffer recording setup completed")
    }
    
    private func setupSystemAudioForBufferRecording() async throws {
        logger.info("ğŸ”§ Setting up system audio for buffer recording...")
        
        do {
            logger.info("Getting shareable content...")
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            logger.info("Found \(content.displays.count) displays, \(content.applications.count) applications")
            
            guard let display = content.displays.first else {
                throw RecordingError.noDisplayFound
            }
            logger.info("Using display: \(display.displayID)")
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
            let filter = SCContentFilter(display: display, excludingApplications: [], exceptingWindows: [])
            let configuration = SCStreamConfiguration()
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£è¨­å®š
            configuration.capturesAudio = true
            configuration.sampleRate = 44100
            configuration.channelCount = 2
            configuration.excludesCurrentProcessAudio = true
            
            // ãƒ“ãƒ‡ã‚ªè¨­å®šã¯æœ€å°ã«
            configuration.width = 100
            configuration.height = 100
            configuration.minimumFrameInterval = CMTime(value: 1, timescale: 1)
            
            logger.info("Creating SCStream with system audio config...")
            logger.info("Audio capture enabled: \(configuration.capturesAudio)")
            logger.info("Sample rate: \(configuration.sampleRate), Channels: \(configuration.channelCount)")
            
            captureSession = SCStream(filter: filter, configuration: configuration, delegate: self)
            
            guard let stream = captureSession else {
                logger.error("Failed to create SCStream object")
                throw RecordingError.screenCaptureKitError(NSError(domain: "MacRecode", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to create SCStream"]))
            }
            logger.info("SCStream created successfully")
            
            // ã‚·ã‚¹ãƒ†ãƒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã«é€ã‚‹å‡ºåŠ›ã‚’è¨­å®š
            logger.info("Adding audio stream output for buffer recording...")
            try stream.addStreamOutput(self, type: .audio, sampleHandlerQueue: recordingQueue)
            logger.info("Audio stream output added")
            
            // ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
            logger.info("Starting ScreenCaptureKit capture...")
            try await stream.startCapture()
            
            logger.info("âœ… ScreenCaptureKit system audio buffer recording started successfully")
        } catch {
            logger.error("ScreenCaptureKit setup failed: \(error.localizedDescription)")
            logger.error("Error details: \(error)")
            
            if let nsError = error as NSError? {
                logger.error("Error domain: \(nsError.domain)")
                logger.error("Error code: \(nsError.code)")
                logger.error("Error userInfo: \(nsError.userInfo)")
            }
            
            throw RecordingError.screenCaptureKitError(error)
        }
    }
    
    // MARK: - Private Helper Methods
    
    private func setupMicrophoneAudioEngine(outputURL: URL) throws {
        // AVAudioEngineã®åˆæœŸåŒ–
        audioEngine = AVAudioEngine()
        guard let engine = audioEngine else {
            throw RecordingError.setupFailed("Failed to create audio engine")
        }
        
        let inputNode = engine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        logger.info("Input audio format: \(recordingFormat)")
        
        // å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        do {
            audioFile = try AVAudioFile(forWriting: outputURL, settings: recordingFormat.settings)
            logger.info("Audio file created with format: \(recordingFormat)")
            logger.info("Audio file path: \(outputURL.path)")
        } catch {
            throw RecordingError.setupFailed("Failed to create audio file: \(error.localizedDescription)")
        }
        
        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã‚¿ãƒƒãƒ—ã‚’è¨­å®š
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] (buffer: AVAudioPCMBuffer, time: AVAudioTime) in
            do {
                try self?.audioFile?.write(from: buffer)
            } catch {
                self?.logger.error("Failed to write audio buffer: \(error.localizedDescription)")
            }
        }
        
        logger.info("Audio engine setup completed")
    }
    
    private func setupSystemAudioCapture(outputURL: URL) async throws {
        do {
            logger.info("Getting shareable content...")
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: false)
            logger.info("Found \(content.displays.count) displays, \(content.applications.count) applications")
            
            guard let display = content.displays.first else {
                throw RecordingError.noDisplayFound
            }
            logger.info("Using display: \(display.displayID)")
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
            // å…¨ã¦ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®éŸ³å£°ã‚’å«ã‚ã‚‹
            let filter = SCContentFilter(display: display, excludingApplications: [], exceptingWindows: [])
            let configuration = SCStreamConfiguration()
            
            // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£è¨­å®š
            configuration.capturesAudio = true
            configuration.sampleRate = 44100
            configuration.channelCount = 2
            configuration.excludesCurrentProcessAudio = true // è‡ªåˆ†ã®ã‚¢ãƒ—ãƒªã®éŸ³å£°ã¯é™¤å¤–
            
            // ãƒ“ãƒ‡ã‚ªè¨­å®šã¯æœ€å°ã«ï¼ˆã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®ã¿ã§ã‚‚å¿…è¦ï¼‰
            configuration.width = 100
            configuration.height = 100
            configuration.minimumFrameInterval = CMTime(value: 1, timescale: 1)
            
            logger.info("Creating SCStream with system audio config...")
            logger.info("Audio capture enabled: \(configuration.capturesAudio)")
            logger.info("Sample rate: \(configuration.sampleRate), Channels: \(configuration.channelCount)")
            logger.info("Excludes current process audio: \(configuration.excludesCurrentProcessAudio)")
            
            captureSession = SCStream(filter: filter, configuration: configuration, delegate: self)
            
            guard let stream = captureSession else {
                logger.error("Failed to create SCStream object")
                throw RecordingError.screenCaptureKitError(NSError(domain: "MacRecode", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to create SCStream"]))
            }
            logger.info("SCStream created successfully")
            
            // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’å…ˆã«è¡Œã†
            try setupSystemAudioFile(outputURL: outputURL)
            logger.info("Audio file setup completed")
            
            logger.info("Adding audio stream output...")
            try stream.addStreamOutput(self, type: .audio, sampleHandlerQueue: recordingQueue)
            logger.info("Audio stream output added")
            
            // ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹å‰ã«å°‘ã—å¾…æ©Ÿ
            logger.info("Starting ScreenCaptureKit capture...")
            try await Task.sleep(nanoseconds: 100_000_000) // 100mså¾…æ©Ÿ
            try await stream.startCapture()
            
            logger.info("ScreenCaptureKit system audio capture started successfully")
        } catch {
            logger.error("ScreenCaptureKit setup failed: \(error.localizedDescription)")
            logger.error("Error details: \(error)")
            
            // å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            if let nsError = error as NSError? {
                logger.error("Error domain: \(nsError.domain)")
                logger.error("Error code: \(nsError.code)")
                logger.error("Error userInfo: \(nsError.userInfo)")
            }
            
            throw RecordingError.screenCaptureKitError(error)
        }
    }
    
    private func setupSystemAudioFile(outputURL: URL) throws {
        logger.info("ğŸ—‚ Creating system audio file: \(outputURL.lastPathComponent)")
        
        // ã‚ˆã‚Šäº’æ›æ€§ã®é«˜ã„CAFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatLinearPCM,
            AVSampleRateKey: 44100.0,
            AVNumberOfChannelsKey: 2,
            AVLinearPCMBitDepthKey: 16,
            AVLinearPCMIsFloatKey: false,
            AVLinearPCMIsBigEndianKey: false,
            AVLinearPCMIsNonInterleaved: false
        ]
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèªã¨ä½œæˆ
        let parentDir = outputURL.deletingLastPathComponent()
        if !FileManager.default.fileExists(atPath: parentDir.path) {
            try FileManager.default.createDirectory(at: parentDir, withIntermediateDirectories: true, attributes: nil)
            logger.info("ğŸ“ Created directory: \(parentDir.path)")
        }
        
        // æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
        if FileManager.default.fileExists(atPath: outputURL.path) {
            try FileManager.default.removeItem(at: outputURL)
            logger.info("ğŸ—‘ Removed existing file: \(outputURL.lastPathComponent)")
        }
        
        do {
            audioFile = try AVAudioFile(forWriting: outputURL, settings: settings)
            logger.info("âœ… System audio file created successfully: \(outputURL.path)")
        } catch {
            logger.error("âŒ Failed to create system audio file: \(error)")
            logger.error("   URL: \(outputURL.path)")
            logger.error("   Settings: \(settings)")
            throw RecordingError.setupFailed("Failed to create system audio file: \(error.localizedDescription)")
        }
        
        logger.info("System audio file setup completed")
    }
}

// MARK: - SCStreamOutput Protocol
extension SystemAudioRecorder {
    nonisolated public func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard type == .audio else { 
            // ãƒ“ãƒ‡ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã¯ç„¡è¦–
            return 
        }
        
        // éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã®å—ä¿¡ã‚’ãƒ­ã‚°ï¼ˆæœ€åˆã®1å›ã®ã¿ï¼‰
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        if frameCount > 0 {
            Task { @MainActor in
                if self.lastAudioLogTime == nil {
                    self.logger.info("ğŸ“» System audio capture active: \(frameCount) frames received")
                    self.lastAudioLogTime = Date()
                    
                    if self.isBufferRecording {
                        self.logger.info("ğŸµ System audio streaming to memory buffers")
                    }
                }
            }
        }
        
        recordingQueue.async { [weak self] in
            guard let self = self else { return }
            
            // CMSampleBufferã‚’AVAudioPCMBufferã«å¤‰æ›
            guard let audioBuffer = self.createAudioBuffer(from: sampleBuffer) else {
                Task { @MainActor in
                    self.logger.error("Failed to create audio buffer from sample buffer")
                }
                return
            }
            
            Task { @MainActor in
                guard self.isRecording else { return }
                
                if self.isBufferRecording {
                    // ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡éŒ²éŸ³ã®å ´åˆ: ãƒãƒƒãƒ•ã‚¡ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«é€ä¿¡
                    self.bufferManager?.addSystemAudioBuffer(audioBuffer)
                } else {
                    // é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«éŒ²éŸ³ã®å ´åˆ: ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
                    do {
                        try self.audioFile?.write(from: audioBuffer)
                    } catch {
                        self.logger.error("Failed to write system audio buffer: \(error.localizedDescription)")
                    }
                }
            }
        }
    }
    
    nonisolated private func createAudioBuffer(from sampleBuffer: CMSampleBuffer) -> AVAudioPCMBuffer? {
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer) else {
            return nil
        }
        
        let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription)
        guard let description = audioStreamBasicDescription else {
            return nil
        }
        
        var streamDescription = description.pointee
        guard let format = AVAudioFormat(streamDescription: &streamDescription) else {
            return nil
        }
        
        let frameCount = CMSampleBufferGetNumSamples(sampleBuffer)
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return nil
        }
        
        buffer.frameLength = AVAudioFrameCount(frameCount)
        
        guard let audioBlockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else {
            return nil
        }
        
        var dataPointer: UnsafeMutablePointer<Int8>?
        var length: Int = 0
        
        let status = CMBlockBufferGetDataPointer(audioBlockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &length, dataPointerOut: &dataPointer)
        
        guard status == noErr, let pointer = dataPointer else {
            return nil
        }
        
        memcpy(buffer.audioBufferList.pointee.mBuffers.mData, pointer, length)
        
        return buffer
    }
}